{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on the World Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know about cleaning and exploring a dataset, we will now train a simple linear regression model on a set of data. We'll use the world population data from the Analyse Supplementary Exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>58055.0</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "      <td>105264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>9938414.0</td>\n",
       "      <td>10152331.0</td>\n",
       "      <td>10372630.0</td>\n",
       "      <td>10604346.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "      <td>35530081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGO</td>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>6203299.0</td>\n",
       "      <td>6309770.0</td>\n",
       "      <td>6414995.0</td>\n",
       "      <td>6523791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "      <td>29784193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALB</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>1965598.0</td>\n",
       "      <td>2022272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>19647.0</td>\n",
       "      <td>20758.0</td>\n",
       "      <td>21890.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "      <td>76965.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Code       1960       1961       1962       1963       1964  \\\n",
       "0          ABW    54211.0    55438.0    56225.0    56695.0    57032.0   \n",
       "1          AFG  8996351.0  9166764.0  9345868.0  9533954.0  9731361.0   \n",
       "2          AGO  5643182.0  5753024.0  5866061.0  5980417.0  6093321.0   \n",
       "3          ALB  1608800.0  1659800.0  1711319.0  1762621.0  1814135.0   \n",
       "4          AND    13411.0    14375.0    15370.0    16412.0    17469.0   \n",
       "\n",
       "        1965        1966        1967        1968     ...            2008  \\\n",
       "0    57360.0     57715.0     58055.0     58386.0     ...        101353.0   \n",
       "1  9938414.0  10152331.0  10372630.0  10604346.0     ...      27294031.0   \n",
       "2  6203299.0   6309770.0   6414995.0   6523791.0     ...      21759420.0   \n",
       "3  1864791.0   1914573.0   1965598.0   2022272.0     ...       2947314.0   \n",
       "4    18549.0     19647.0     20758.0     21890.0     ...         83861.0   \n",
       "\n",
       "         2009        2010        2011        2012        2013        2014  \\\n",
       "0    101453.0    101669.0    102053.0    102577.0    103187.0    103795.0   \n",
       "1  28004331.0  28803167.0  29708599.0  30696958.0  31731688.0  32758020.0   \n",
       "2  22549547.0  23369131.0  24218565.0  25096150.0  25998340.0  26920466.0   \n",
       "3   2927519.0   2913021.0   2905195.0   2900401.0   2895092.0   2889104.0   \n",
       "4     84462.0     84449.0     83751.0     82431.0     80788.0     79223.0   \n",
       "\n",
       "         2015        2016        2017  \n",
       "0    104341.0    104822.0    105264.0  \n",
       "1  33736494.0  34656032.0  35530081.0  \n",
       "2  27859305.0  28813463.0  29784193.0  \n",
       "3   2880703.0   2876101.0   2873457.0  \n",
       "4     78014.0     77281.0     76965.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the future population of a particular country might be. To do this, we're going to ignore the 2017 column from our data, and use this as a metric for testing the accuracy of our prediction.\n",
    "\n",
    "First, however, we need to formulate our data such that the sklearn's `LinearRegression` class can train on our data. To do this, we will write a function that takes as input a country code and return a 2-d numpy array that contains the year and the measured population. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a `str` as input and return a numpy `array` type as output.\n",
    "* The array should only have two columns containing the year and the population, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
    "* The values within the array should be of type `int`.\n",
    "\n",
    "_**Hint:**_\n",
    "You'll first need to filter the dataframe on the given country code. Once you do this, you'll notice the DataFrame has the years as columns. You can just use `pd.melt(df)` and slice your data to get to the right format, before using `.get_values()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_pop(code):\n",
    "    # your code here\n",
    "    df = df_pop[df_pop['Country Code'] == code]\n",
    "    melted = pd.melt(df)\n",
    "    v = melted[1:]\n",
    "    length = len(v['variable'])\n",
    "\n",
    "    pop = []\n",
    "    for i in range(length):\n",
    "        pop.append([int(v['variable'].iloc[i]),int(v['value'].iloc[i])])\n",
    "\n",
    "    pop_array = np.array(pop)\n",
    "    \n",
    "    return pop_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1960,  54211],\n",
       "       [  1961,  55438],\n",
       "       [  1962,  56225],\n",
       "       [  1963,  56695],\n",
       "       [  1964,  57032],\n",
       "       [  1965,  57360],\n",
       "       [  1966,  57715],\n",
       "       [  1967,  58055],\n",
       "       [  1968,  58386],\n",
       "       [  1969,  58726],\n",
       "       [  1970,  59063],\n",
       "       [  1971,  59440],\n",
       "       [  1972,  59840],\n",
       "       [  1973,  60243],\n",
       "       [  1974,  60528],\n",
       "       [  1975,  60657],\n",
       "       [  1976,  60586],\n",
       "       [  1977,  60366],\n",
       "       [  1978,  60103],\n",
       "       [  1979,  59980],\n",
       "       [  1980,  60096],\n",
       "       [  1981,  60567],\n",
       "       [  1982,  61345],\n",
       "       [  1983,  62201],\n",
       "       [  1984,  62836],\n",
       "       [  1985,  63026],\n",
       "       [  1986,  62644],\n",
       "       [  1987,  61833],\n",
       "       [  1988,  61079],\n",
       "       [  1989,  61032],\n",
       "       [  1990,  62149],\n",
       "       [  1991,  64622],\n",
       "       [  1992,  68235],\n",
       "       [  1993,  72504],\n",
       "       [  1994,  76700],\n",
       "       [  1995,  80324],\n",
       "       [  1996,  83200],\n",
       "       [  1997,  85451],\n",
       "       [  1998,  87277],\n",
       "       [  1999,  89005],\n",
       "       [  2000,  90853],\n",
       "       [  2001,  92898],\n",
       "       [  2002,  94992],\n",
       "       [  2003,  97017],\n",
       "       [  2004,  98737],\n",
       "       [  2005, 100031],\n",
       "       [  2006, 100832],\n",
       "       [  2007, 101220],\n",
       "       [  2008, 101353],\n",
       "       [  2009, 101453],\n",
       "       [  2010, 101669],\n",
       "       [  2011, 102053],\n",
       "       [  2012, 102577],\n",
       "       [  2013, 103187],\n",
       "       [  2014, 103795],\n",
       "       [  2015, 104341],\n",
       "       [  2016, 104822],\n",
       "       [  2017, 105264]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_year_pop('ABW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "get_year_pop('ABW')\n",
    "```\n",
    "> ```\n",
    "array([[  1960,  54211],\n",
    "       [  1961,  55438],\n",
    "       [  1962,  56225],\n",
    "        ...\n",
    "       [  2016, 104822],\n",
    "       [  2017, 105264]])\n",
    "```\n",
    "\n",
    "```python\n",
    "get_year_pop('ABW').shape == (58, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have have our data, we need to split this into a set of variables we will be training on, and the set of variables that we will make our predictions on. In this case, we're splitting the values such that we train on all but the last year in our dataset. We also need to split our data into the predictive features (denoted `X`) and the response (denoted `y`). \n",
    "\n",
    "Write a function that will take as input a 2-d numpy array and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features / response of the training set, and `(X-test, y_test)` are the feautes / response of the testing set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a 2-d numpy `array` as input.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "* `(X_test, y_test)` should just be the last entry of the given input. They should also be the form of an `array`, and not as a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_response_split(arr):\n",
    "    \n",
    "    X_train = arr[:-1,0]\n",
    "    y_train = arr[:-1,1]\n",
    "    X_test = np.array([arr[-1,0]])\n",
    "    y_test = np.array([arr[-1,1]])\n",
    "    x = tuple([X_train,y_train])\n",
    "    y = tuple([X_test,y_test])\n",
    "    \n",
    "    return tuple([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,\n",
       "         1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981,\n",
       "         1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992,\n",
       "         1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
       "         2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
       "         2015, 2016]),\n",
       "  array([ 54211,  55438,  56225,  56695,  57032,  57360,  57715,  58055,\n",
       "          58386,  58726,  59063,  59440,  59840,  60243,  60528,  60657,\n",
       "          60586,  60366,  60103,  59980,  60096,  60567,  61345,  62201,\n",
       "          62836,  63026,  62644,  61833,  61079,  61032,  62149,  64622,\n",
       "          68235,  72504,  76700,  80324,  83200,  85451,  87277,  89005,\n",
       "          90853,  92898,  94992,  97017,  98737, 100031, 100832, 101220,\n",
       "         101353, 101453, 101669, 102053, 102577, 103187, 103795, 104341,\n",
       "         104822])),\n",
       " (array([2017]), array([105264])))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_year_pop('ABW')\n",
    "feature_response_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "data = get_year_pop('ABW')\n",
    "feature_response_split(data)\n",
    "```\n",
    "> ```\n",
    "((array([1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,\n",
    "         1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981,\n",
    "         1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992,\n",
    "         1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
    "         2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
    "         2015, 2016]),\n",
    "  array([ 54211,  55438,  56225,  56695,  57032,  57360,  57715,  58055,\n",
    "          58386,  58726,  59063,  59440,  59840,  60243,  60528,  60657,\n",
    "          60586,  60366,  60103,  59980,  60096,  60567,  61345,  62201,\n",
    "          62836,  63026,  62644,  61833,  61079,  61032,  62149,  64622,\n",
    "          68235,  72504,  76700,  80324,  83200,  85451,  87277,  89005,\n",
    "          90853,  92898,  94992,  97017,  98737, 100031, 100832, 101220,\n",
    "         101353, 101453, 101669, 102053, 102577, 103187, 103795, 104341,\n",
    "         104822])),\n",
    " (array([2017]), array([105264])))\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have formatted our data, we can fit a model using sklearn's `LinearRegression()` class. We'll write a function that will take as input the features and response variables that we created in the last question, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `LinearRegression` model.\n",
    "* The returned model should be fitted to the data.\n",
    "\n",
    "_**Hint:**_\n",
    "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    # Fitting Simple Linear Regression to the Training set\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor = LinearRegression()\n",
    "    model = regressor.fit(np.array(X_train).reshape(-1,1), y_train.reshape(-1,1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104770.18984962]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_year_pop('ABW')\n",
    "(X_train, y_train), _ = feature_response_split(data)\n",
    "\n",
    "train_model(X_train, y_train).predict([[2017]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "train_model(X_train, y_train).predict([[2017]]) == array([[104770.18984962]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now like to test our model using the testing data that we produced from Question 2. This test should give the residual sum of squares, which for your convenience is written as\n",
    "$$\n",
    "RSS = \\sum_{i=1}^N (p_i - y_i)^2,\n",
    "$$\n",
    "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2. \n",
    "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
    "* The output should be a `float` rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    # your code here\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rss = np.sum((model.predict(np.array(X_test).reshape(-1,1)) - y_test)**2)\n",
    "    rss = round(rss,2)\n",
    "    return rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243848.46"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_year_pop('ABW')\n",
    "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
    "lm = train_model(X_train, y_train)\n",
    "\n",
    "test_model(lm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "test_model(lm, X_test, y_test) == 243848.46\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
